{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект исследования поездок такси"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Бизнес-анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Цель бизнеса\n",
    "\n",
    "Компания *** собирает данных для всех поездок желтого такси.\n",
    "\n",
    "Попробуем воспользоваться этими данных, чтобы получить выгоду для бизнеса, для примера, пусть это будет маленький парк такси или один таксист.\n",
    "\n",
    "Прибыль за смену\n",
    "\n",
    "$$ Опер.прибыль = Выручка - Опер. расходы $$\n",
    "\n",
    "$$ Выручка = \\sum_{i=1}^n [F_{Счетчик}(Расстояние, Время, Скорость) + F_{чаевые}(F_{Счетчик})] $$\n",
    "\n",
    "$$ Опер. расходы = F_{Бензин}(Расход, Расстояние) $$\n",
    "\n",
    "$$ Опер.прибыль = \\sum_{i=1}^n [F_{Счетчик}(Расстояние, Время, Скорость) + F_{чаевые} - $$\n",
    "\n",
    "$$ - F_{Бензин}(Расход, Расстояние)] - F_{Бензин}(Расход, Расстояние) $$\n",
    "\n",
    "Тариф - 2.5 доллара стоит остановить машину; если она едет от десяти километров в час, то каждые 320 метров (одна пятая мили) обойдутся пассажиру в 0.5 доллара. Если скорость меньше или машина стоит в пробке, то каждая минута также будет стоить 0.5 доллара.\n",
    "\n",
    "Бензин\n",
    "\n",
    "150 центов за галлон (1 гал = 4,54609 л)\n",
    "\n",
    "2,5 $ за 4,54609 л\n",
    "\n",
    "0.5 $ за л\n",
    "\n",
    "Расход 10 л/100 км"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Цель анализа данных\n",
    "\n",
    "В работе мы можем влиять только на выбор водителя - в какое время суток выходить на работу, в какой день недели и остаться в районе или ехать в другой за заказом.\n",
    "\n",
    "Помощь в принятии решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q plotly geopandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Анализ данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Исходные данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import urllib\n",
    "import zipfile\n",
    "from tqdm.notebook import tqdm\n",
    "import bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_rawdata = 'data/green_taxi/'\n",
    "path_to_geoinfo = 'data/shape/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(path_to_rawdata):\n",
    "    os.mkdir(path_to_rawdata)\n",
    "if not os.path.exists(path_to_geoinfo):\n",
    "    os.mkdir(path_to_geoinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_range = {\n",
    "    '2017': range(13),\n",
    "    '2018': range(13),\n",
    "    '2019': range(13),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = []\n",
    "data_url = \"https://s3.amazonaws.com/nyc-tlc/trip+data/\"\n",
    "for year in download_range.keys():\n",
    "    for month in download_range[year]:\n",
    "        filename = 'green_tripdata_{0}-{1:0=2d}.csv'.format(year, month)\n",
    "        path_to_file = os.path.join(path_to_rawdata, filename)\n",
    "        if not os.path.exists(path_to_file) and not os.path.exists(path_to_file + '.bz2'):\n",
    "            urllib.request.urlretrieve(data_url + filename, path_to_file)\n",
    "            url_list.append(data_url + filename)\n",
    "url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_load(url, chunksize=100000):\n",
    "    with urllib.request.urlopen(url) as f:\n",
    "        while True:\n",
    "            chunk = f.readlines(chunksize)\n",
    "            if not chunk:\n",
    "                break\n",
    "            yield b''.join(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_compress(csv_url):\n",
    "    filename = csv_url.split('/')[-1] + '.bz2'\n",
    "    path_to_file = os.path.join(path_to_rawdata, filename)\n",
    "    with open(path_to_file, 'wb') as f:\n",
    "        comp = bz2.BZ2Compressor()\n",
    "        for chunk in chunk_load(csv_url):\n",
    "            f.write(comp.compress(chunk))\n",
    "        f.write(comp.flush())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool(4)\n",
    "pool.map(load_compress, url_list)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"taxi_zones.zip\"):\n",
    "    urllib.request.urlretrieve(\"https://s3.amazonaws.com/nyc-tlc/misc/taxi_zones.zip\", \"taxi_zones.zip\")\n",
    "    with zipfile.ZipFile(\"taxi_zones.zip\", \"r\") as zip_ref:\n",
    "        zip_ref.extractall(path_to_geoinfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Исследование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка полей в файлах:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = glob.glob(os.path.join(path_to_rawdata, '*'))\n",
    "filelist.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = []\n",
    "for f in filelist:\n",
    "    cols.append(list(pd.read_csv(f, nrows=0).columns))\n",
    "pd.DataFrame(cols, index=[x.split('/')[-1] for x in filelist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filelist[-1], nrows=5)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['VendorID', 'store_and_fwd_flag', 'extra', 'mta_tax', 'ehail_fee', 'improvement_surcharge','congestion_surcharge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['RatecodeID', 'PULocationID', 'DOLocationID', 'payment_type', 'trip_type']\n",
    "numerical_cols = ['passenger_count', 'trip_distance', 'fare_amount', 'tip_amount', \n",
    "                  'tolls_amount', 'total_amount']\n",
    "datetime_cols = ['lpep_pickup_datetime', 'lpep_dropoff_datetime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set(rc={'figure.figsize':(15,8)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lC-Ulysdzm85"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P1kT0sq2zm8-"
   },
   "outputs": [],
   "source": [
    "MEMORY_SIZE = '5g'\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .config('spark.driver.memory', MEMORY_SIZE) \\\n",
    "    .appName('spark-taxi') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E6HUAbZXzm9D"
   },
   "outputs": [],
   "source": [
    "schema_trips = StructType([StructField('VendorID',ByteType(),True),\n",
    "                           StructField('lpep_pickup_datetime',TimestampType(),True),\n",
    "                           StructField('lpep_dropoff_datetime',TimestampType(),True),\n",
    "                           StructField('store_and_fwd_flag',StringType(),True),\n",
    "                           StructField('RatecodeID',ByteType(),True),\n",
    "                           StructField('PULocationID',IntegerType(),True),\n",
    "                           StructField('DOLocationID',IntegerType(),True),\n",
    "                           StructField('passenger_count',ByteType(),True),\n",
    "                           StructField('trip_distance',FloatType(),True),\n",
    "                           StructField('fare_amount',FloatType(),True),\n",
    "                           StructField('extra',FloatType(),True),\n",
    "                           StructField('mta_tax',FloatType(),True),\n",
    "                           StructField('tip_amount',FloatType(),True),\n",
    "                           StructField('tolls_amount',FloatType(),True),\n",
    "                           StructField('ehail_fee',FloatType(),True),\n",
    "                           StructField('improvement_surcharge',FloatType(),True),\n",
    "                           StructField('total_amount',FloatType(),True),\n",
    "                           StructField('payment_type',ByteType(),True),\n",
    "                           StructField('trip_type',ByteType(),True),\n",
    "                           StructField('congestion_surcharge',FloatType(),True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gXjT9z34zm9J"
   },
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .format('csv') \\\n",
    "    .schema(schema_trips) \\\n",
    "    .option('header', 'true') \\\n",
    "    .option('delimiter', ',') \\\n",
    "    .load(path_to_rawdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['VendorID', 'store_and_fwd_flag', 'extra', 'mta_tax', 'ehail_fee', 'improvement_surcharge','congestion_surcharge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(*drop_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сразу добавим дополнительные признаки для анализа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_secs_col = col(\"lpep_dropoff_datetime\").cast(\"long\") - col(\"lpep_pickup_datetime\").cast(\"long\")\n",
    "df = df.withColumn(\"duration\", diff_secs_col / 60) \\\n",
    "        .withColumn(\"speed\", col('trip_distance') / (col('duration') / 60)) \\\n",
    "        .withColumn(\"hour_pickup\", hour(col('lpep_pickup_datetime'))) \\\n",
    "        .withColumn(\"weekday_pickup\", dayofweek(col('lpep_pickup_datetime'))) \\\n",
    "        .withColumn('date_file', date_trunc('month', to_timestamp(regexp_extract(input_file_name(), r'(\\d+\\-\\d+)', 1), 'yyyy-MM'))) \\\n",
    "        .cache()\n",
    "#df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_len_df = df.count()\n",
    "print(f'Количество строк - {init_len_df}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['RatecodeID', 'PULocationID', 'DOLocationID', 'payment_type', 'trip_type']\n",
    "numerical_cols = ['passenger_count', 'trip_distance', 'fare_amount', 'tip_amount', \n",
    "                  'tolls_amount', 'total_amount']\n",
    "datetime_cols = ['lpep_pickup_datetime', 'lpep_dropoff_datetime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Анализ дат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date, max_date = df.select(min(\"lpep_pickup_datetime\"), max(\"lpep_pickup_datetime\")).first()\n",
    "print(min_date, max_date)\n",
    "total_hours = (max_date - min_date).days * 24\n",
    "print(total_hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(date_trunc('month', col('lpep_pickup_datetime')) == df['date_file']).drop('date_file')\n",
    "df = df.filter('lpep_pickup_datetime < lpep_dropoff_datetime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Анализ категориальных признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RatecodeID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RatecodeID_hist = df.groupBy('RatecodeID').count().toPandas()\n",
    "RatecodeID_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='RatecodeID', y='count', data=RatecodeID_hist);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter('RatecodeID < 5').dropna(subset=['RatecodeID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### payment_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "payment_type_hist = df.groupBy('payment_type').count().toPandas()\n",
    "payment_type_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.barplot(x='payment_type', y='count', data=payment_type_hist);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter('payment_type < 3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Анализ количественных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(numerical_cols).describe().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**passenger_count** - поездки без пассажиров?\n",
    "\n",
    "**trip_distance** - нулевая дистанция и огромная дистанция (73 тыс. км)\n",
    "\n",
    "**стоимость поездки** - отрицательные значения и большие максимальные\n",
    "\n",
    "Требуется очистка данных от некорректных значений и выбросов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### passenger_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_count_hist = df.groupBy('passenger_count').count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='passenger_count', y='count', data=passenger_count_hist);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter('passenger_count > 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Показать распределение по районам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### trip_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('trip_distance').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.approxQuantile('trip_distance', [0.05, 0.95], 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(np.linspace(0, 10, 21)) + [10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_distance_hist = df.select('trip_distance').rdd.flatMap(lambda x: x).histogram(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_distance_hist_pd = pd.DataFrame(zip(*trip_distance_hist), columns=['bins', 'count'])\n",
    "#trip_distance_hist_pd['count'] = trip_distance_hist_pd['count'] / total_hours\n",
    "trip_distance_hist_pd['count_log'] = trip_distance_hist_pd['count'].apply(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=trip_distance_hist_pd, x='bins', y='count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(np.arange(0, 30, 1))\n",
    "trip_distance_hist = df.select('trip_distance').rdd.flatMap(lambda x: x).histogram(x)\n",
    "trip_distance_hist_pd = pd.DataFrame(zip(*trip_distance_hist), columns=['bins', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=trip_distance_hist_pd, x='bins', y='count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter('trip_distance >= 0.5').filter('trip_distance < 10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('trip_distance').describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('duration').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.approxQuantile('duration', [0.05, 0.95], 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(np.arange(0, 40, 1)) + [10000]\n",
    "duration_hist = df.select(log('duration')).rdd.flatMap(lambda x: x).histogram(20)\n",
    "duration_hist_pd = pd.DataFrame(zip(*duration_hist), columns=['bins', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=duration_hist_pd, x='bins', y='count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(np.arange(0, 30, 0.5))\n",
    "duration_hist = df.select('duration').rdd.flatMap(lambda x: x).histogram(x)\n",
    "duration_hist_pd = pd.DataFrame(zip(*duration_hist), columns=['bins', 'count'])\n",
    "duration_hist_pd['count_log'] = duration_hist_pd['count'].apply(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=duration_hist_pd, x='bins', y='count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter('duration > 1').filter('duration < 60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('duration').describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('speed').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.approxQuantile('speed', [0.05, 0.95], 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(np.arange(0, 120, 10)) + [5000]\n",
    "speed_hist = df.select('speed').rdd.flatMap(lambda x: x).histogram(x)\n",
    "speed_hist_pd = pd.DataFrame(zip(*speed_hist), columns=['bins', 'count'])\n",
    "speed_hist_pd['count_log'] = speed_hist_pd['count'].apply(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.barplot(data=speed_hist_pd, x='bins', y='count')\n",
    "#g.set_xticklabels([f'{x:.2}' for x in speed_hist_pd['bins']], rotation=45);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(np.arange(0, 20, 0.5))\n",
    "speed_hist = df.select('speed').rdd.flatMap(lambda x: x).histogram(x)\n",
    "speed_hist_pd = pd.DataFrame(zip(*speed_hist), columns=['bins', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=speed_hist_pd, x='bins', y='count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter('speed > 0.5').filter('speed < 100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fare_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('fare_amount').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.approxQuantile('fare_amount', [0.05, 0.95], 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [-100] + list(np.arange(0, 300, 10)) + [10000]\n",
    "fare_amount_hist = df.select('fare_amount').rdd.flatMap(lambda x: x).histogram(x)\n",
    "fare_amount_hist_pd = pd.DataFrame(zip(*fare_amount_hist), columns=['bins', 'count'])\n",
    "fare_amount_hist_pd['count_log'] = fare_amount_hist_pd['count'].apply(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=fare_amount_hist_pd, x='bins', y='count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(np.arange(0, 20, 0.5))\n",
    "fare_amount_hist = df.select('fare_amount').rdd.flatMap(lambda x: x).histogram(x)\n",
    "fare_amount_hist_pd = pd.DataFrame(zip(*fare_amount_hist), columns=['bins', 'count'])\n",
    "fare_amount_hist_pd['count_log'] = fare_amount_hist_pd['count'].apply(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=fare_amount_hist_pd, x='bins', y='count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter('fare_amount >= 3').filter('fare_amount < 150')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Количество строк - {df.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(init_len_df - df.count()) / df.count() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile load.py\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "def load_data(spark, path):\n",
    "    \n",
    "    schema_trips = StructType([StructField('VendorID',ByteType(),True),\n",
    "                               StructField('lpep_pickup_datetime',TimestampType(),True),\n",
    "                               StructField('lpep_dropoff_datetime',TimestampType(),True),\n",
    "                               StructField('store_and_fwd_flag',StringType(),True),\n",
    "                               StructField('RatecodeID',ByteType(),True),\n",
    "                               StructField('PULocationID',IntegerType(),True),\n",
    "                               StructField('DOLocationID',IntegerType(),True),\n",
    "                               StructField('passenger_count',ByteType(),True),\n",
    "                               StructField('trip_distance',FloatType(),True),\n",
    "                               StructField('fare_amount',FloatType(),True),\n",
    "                               StructField('extra',FloatType(),True),\n",
    "                               StructField('mta_tax',FloatType(),True),\n",
    "                               StructField('tip_amount',FloatType(),True),\n",
    "                               StructField('tolls_amount',FloatType(),True),\n",
    "                               StructField('ehail_fee',FloatType(),True),\n",
    "                               StructField('improvement_surcharge',FloatType(),True),\n",
    "                               StructField('total_amount',FloatType(),True),\n",
    "                               StructField('payment_type',ByteType(),True),\n",
    "                               StructField('trip_type',ByteType(),True),\n",
    "                               StructField('congestion_surcharge',FloatType(),True)])\n",
    "    \n",
    "    df = spark.read \\\n",
    "        .format('csv') \\\n",
    "        .schema(schema_trips) \\\n",
    "        .option('header', 'true') \\\n",
    "        .option('delimiter', ',') \\\n",
    "        .load(path)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile filter.py\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "def filter_data(df):\n",
    "    \n",
    "    drop_cols = ['VendorID', 'store_and_fwd_flag', 'extra', 'mta_tax', 'ehail_fee', 'improvement_surcharge','congestion_surcharge']\n",
    "    df = df.drop(*drop_cols)\n",
    "\n",
    "    diff_secs_col = col(\"lpep_dropoff_datetime\").cast(\"long\") - col(\"lpep_pickup_datetime\").cast(\"long\")\n",
    "    df = df.withColumn(\"duration\", (diff_secs_col / 60).cast('int')) \\\n",
    "        .withColumn(\"speed\", col('trip_distance') / (col('duration') / 60)) \\\n",
    "        .withColumn('date_file', date_trunc('month', to_timestamp(regexp_extract(input_file_name(), r'(\\d+\\-\\d+)', 1), 'yyyy-MM')))\n",
    "\n",
    "    \n",
    "    df = df.filter('fare_amount >= 3').filter('fare_amount < 150')\n",
    "    df = df.filter('speed > 0.5').filter('speed < 100')\n",
    "    df = df.filter('duration > 1').filter('duration < 150')\n",
    "    df = df.filter('trip_distance > 0.1').filter('trip_distance < 150')\n",
    "    df = df.filter('passenger_count > 0')\n",
    "    df = df.filter('payment_type < 3')\n",
    "    df = df.filter('RatecodeID < 5')\n",
    "    df = df.filter(date_trunc('month', col('lpep_pickup_datetime')) == df['date_file']).drop('date_file')\n",
    "    df = df.filter('lpep_pickup_datetime < lpep_dropoff_datetime')\n",
    "    df = df.dropna()\n",
    "    \n",
    "    #select_cols = ['lpep_pickup_datetime', 'lpep_dropoff_datetime', 'PULocationID', 'DOLocationID','total_amount']\n",
    "    #df = df.select(select_cols)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Window().partitionBy(\"PULocationID\").orderBy(\"tpep_pickup_datetime\")\n",
    "pause_secs = col(\"tpep_pickup_datetime\").cast(\"long\") - lag(col(\"tpep_pickup_datetime\"), 1).over(w).cast(\"long\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.withColumn(\"pause\", pause_secs).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_rawdata = 'data/green_taxi/green_tripdata_2017-06.csv.bz2'\n",
    "path_to_geoinfo = 'shape/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lC-Ulysdzm85"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filter import filter_data\n",
    "from load import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P1kT0sq2zm8-"
   },
   "outputs": [],
   "source": [
    "MEMORY_SIZE = '5g'\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .config('spark.driver.memory', MEMORY_SIZE) \\\n",
    "    .appName('spark-taxi') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(spark, path_to_rawdata)\n",
    "df = filter_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = df.cache()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XGXpt9CPzm9q"
   },
   "source": [
    "## Карта Нью-Йорка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mcPxmZA2zm9r"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import plotly.express as px\n",
    "import geopandas as gpd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZNyiKoFzzm9y"
   },
   "outputs": [],
   "source": [
    "taxi_zone = gpd.read_file(os.path.join(path_to_geoinfo, 'taxi_zones.shp')).to_crs(\"EPSG:4326\")\n",
    "taxi_zone = taxi_zone.set_index('LocationID')\n",
    "taxi_zone_json = json.loads(taxi_zone.to_json())\n",
    "taxi_zone.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cq9f1k5Yzm93"
   },
   "outputs": [],
   "source": [
    "def plot_maps_region(df, locations_col, color_col):\n",
    "    fig = px.choropleth_mapbox(df, geojson=taxi_zone_json, locations=locations_col, color=color_col,\n",
    "                           color_continuous_scale=\"Viridis\",\n",
    "                           mapbox_style=\"carto-positron\",\n",
    "                           zoom=9.5, center = {\"lat\": 40.7142700, \"lon\": -74.0059700},\n",
    "                           opacity=0.5,\n",
    "                          )\n",
    "    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gqom1Wjbzm98"
   },
   "outputs": [],
   "source": [
    "count_by_zones = df.groupBy('PULocationID').count().toPandas()\n",
    "count_by_zones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_by_zones['count'] = count_by_zones['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_by_zones.sort_values('count',ascending=False).head(20)['PULocationID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A6WG1TOwzm-B"
   },
   "outputs": [],
   "source": [
    "plot_maps_region(count_by_zones, 'PULocationID', 'count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hYh0xofAzm-H"
   },
   "source": [
    "## Доля кредитных карт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b1ph6s-1zm-I"
   },
   "outputs": [],
   "source": [
    "credit_by_zones = df.filter('payment_type == 1').groupBy('PULocationID').count().toPandas()\n",
    "cash_by_zones = df.filter('payment_type == 2').groupBy('PULocationID').count().toPandas()\n",
    "paynement_by_zones = cash_by_zones.merge(credit_by_zones, on='PULocationID',suffixes=('_cash', '_credit'))\n",
    "paynement_by_zones['credit/cash'] = paynement_by_zones['count_credit'] / (paynement_by_zones['count_cash'] + paynement_by_zones['count_credit']) * 100\n",
    "paynement_by_zones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rpkFuHTDzm-N"
   },
   "outputs": [],
   "source": [
    "plot_maps_region(paynement_by_zones, 'PULocationID', 'credit/cash')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "larxFJKxzm-R"
   },
   "source": [
    "## Процент чаевых"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f5gBO8PBzm-R"
   },
   "outputs": [],
   "source": [
    "tips_by_zones = df.filter('payment_type == 1') \\\n",
    "    .withColumn('tip_prop', col('tip_amount') / col('total_amount') * 100) \\\n",
    "    .groupBy('PULocationID') \\\n",
    "    .agg({'tip_prop':'avg'}) \\\n",
    "    .toPandas()\n",
    "tips_by_zones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zFojE84Azm-V"
   },
   "outputs": [],
   "source": [
    "plot_maps_region(tips_by_zones.merge(count_by_zones).query('count > 10'), 'PULocationID', 'avg(tip_prop)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tjzf3ivTzm-a"
   },
   "source": [
    "В среднем чаевые составляют 15%, но есть районы больше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sMqxBrYyzm-c"
   },
   "source": [
    "## Средний заработок в час"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Window().partitionBy(\"PULocationID\").orderBy(\"lpep_pickup_datetime\")\n",
    "pause_secs = col(\"lpep_pickup_datetime\").cast(\"long\") - lag(col(\"lpep_pickup_datetime\"), 1).over(w).cast(\"long\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"duration_wait\", pause_secs).dropna()\n",
    "df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BQHCUEHuzm-t"
   },
   "outputs": [],
   "source": [
    "fare_hour_by_reg = df \\\n",
    "        .withColumn(\"fare_hour\", (col('fare_amount') / ((col('duration') + col('duration_wait') / 60) / 60))) \\\n",
    "        .groupBy('PULocationID') \\\n",
    "        .agg(mean('fare_hour').alias('mean_fare_hour')) \\\n",
    "        .toPandas()\n",
    "fare_hour_by_reg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare_hour_by_reg.sort_values('mean_fare_hour', ascending=False).head(10)['PULocationID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rzVZDh0Kzm-y"
   },
   "outputs": [],
   "source": [
    "plot_maps_region(fare_hour_by_reg.merge(count_by_zones).query('count > 10'), 'PULocationID', 'mean_fare_hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "le8rILfbzm_K"
   },
   "source": [
    "## Чаевые по времени суток"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UKhlCzFBzm_L"
   },
   "outputs": [],
   "source": [
    "tips_by_hour = df \\\n",
    "    .withColumn('tip_prop', df['tip_amount'] / df['total_amount'] * 100) \\\n",
    "    .groupby('hour_pickup') \\\n",
    "    .agg({'tip_prop':'avg'}) \\\n",
    "    .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "udis36c5zm_P"
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=tips_by_hour, x='hour_pickup', y='avg(tip_prop)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vRUxrWLczm_U"
   },
   "outputs": [],
   "source": [
    "tips_by_weekday = df.filter('payment_type == 1 AND PULocationID == 132') \\\n",
    "    .withColumn('tip_prop', df['tip_amount'] / df['total_amount'] * 100) \\\n",
    "    .groupby('weekday_pickup') \\\n",
    "    .agg({'tip_prop':'avg'}) \\\n",
    "    .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jfB8kF39zm_Z"
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=tips_by_weekday, x='weekday_pickup', y='avg(tip_prop)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1WHVU0eazm_f"
   },
   "source": [
    "Чаевые не зависят от времени суток и дней недели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m9kJ6fs2zm_g"
   },
   "source": [
    "## Время ожидания заказа\n",
    "\n",
    "Пропорционально количеству поездок, но благодаря абсолютной величине можно оценить ехать в другой район или остаться ждать заказ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q1lcqziGzm_u"
   },
   "outputs": [],
   "source": [
    "minute_by_zones = df.groupBy('PULocationID').agg(mean('duration_wait').alias('mean_wait')).toPandas()\n",
    "minute_by_zones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VdRrQJ3Dzm_1"
   },
   "outputs": [],
   "source": [
    "plot_maps_region(minute_by_zones.query('mean_wait < 6000'), 'PULocationID', 'mean_wait')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cEVD9UwMzm_4"
   },
   "source": [
    "Время ожидания заказа менее 30 минут только в центральных районах и аэропорте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Временные ряды"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BkJ1-rfMzm_4"
   },
   "source": [
    "## Продолжительность поездок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GpAEk3V1znAG"
   },
   "outputs": [],
   "source": [
    "timeseries = df \\\n",
    "        .withColumn(\"datetime_day\", date_trunc('day', col('lpep_pickup_datetime'))) \\\n",
    "        .groupBy('datetime_day') \\\n",
    "        .agg(mean('duration').alias('duration')) \\\n",
    "        .orderBy('datetime_day') \\\n",
    "        .toPandas()\n",
    "timeseries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(data_frame=timeseries,x='datetime_day', y='duration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['PULocationID', 'DOLocationID']).count().filter(col('PULocationID') != col('DOLocationID')).orderBy('count', ascending=False).limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = df.filter('PULocationID == 7 AND DOLocationID == 7') \\\n",
    "        .withColumn(\"datetime_day\", date_trunc('day', col('lpep_pickup_datetime'))) \\\n",
    "        .groupBy('datetime_day') \\\n",
    "        .agg(mean('duration').alias('duration')) \\\n",
    "        .orderBy('datetime_day') \\\n",
    "        .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(data_frame=timeseries,x='datetime_day', y='duration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чаевые"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = df.filter('payment_type == 1') \\\n",
    "        .withColumn('tip_prop', df['tip_amount'] / df['fare_amount'] * 100) \\\n",
    "        .withColumn(\"datetime_day\", date_trunc('day', col('lpep_pickup_datetime'))) \\\n",
    "        .groupBy('datetime_day') \\\n",
    "        .agg(mean('tip_prop').alias('tip_prop')) \\\n",
    "        .orderBy('datetime_day') \\\n",
    "        .toPandas()\n",
    "px.line(data_frame=timeseries,x='datetime_day', y='tip_prop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ожидание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = df \\\n",
    "        .withColumn(\"datetime_day\", date_trunc('day', col('lpep_pickup_datetime'))) \\\n",
    "        .groupBy('datetime_day') \\\n",
    "        .count() \\\n",
    "        .orderBy('datetime_day') \\\n",
    "        .toPandas()\n",
    "px.line(data_frame=timeseries,x='datetime_day', y='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = df \\\n",
    "        .withColumn(\"datetime_day\", date_trunc('day', col('lpep_pickup_datetime'))) \\\n",
    "        .groupBy('datetime_day') \\\n",
    "        .agg(mean('fare_amount').alias('fare')) \\\n",
    "        .orderBy('datetime_day') \\\n",
    "        .toPandas()\n",
    "px.line(data_frame=timeseries,x='datetime_day', y='fare')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trip_distanse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = df \\\n",
    "        .withColumn(\"datetime_day\", date_trunc('day', col('lpep_pickup_datetime'))) \\\n",
    "        .groupBy('datetime_day') \\\n",
    "        .agg(mean('trip_distance').alias('trip_distance')) \\\n",
    "        .orderBy('datetime_day') \\\n",
    "        .toPandas()\n",
    "px.line(data_frame=timeseries,x='datetime_day', y='trip_distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, OneHotEncoder, OneHotEncoderEstimator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.select(date_trunc('hour', col('lpep_pickup_datetime')).alias('lpep_pickup_datetime'),\n",
    "                'PULocationID', 'DOLocationID', log('duration').alias('duration'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumn('month_1', add_months('lpep_pickup_datetime', -1))\n",
    "data.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = data.select(col('lpep_pickup_datetime').alias('lpep_pickup_datetime_'), \n",
    "                   col('PULocationID').alias('PULocationID_'),\n",
    "                   col('DOLocationID').alias('DOLocationID_'), \n",
    "                   col('duration').alias('duration_')) \\\n",
    "            .groupBy(['lpep_pickup_datetime_', 'PULocationID_', 'DOLocationID_']).agg(mean('duration_'))\n",
    "temp.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = [data.month_1 == temp.lpep_pickup_datetime_, \n",
    "        data.PULocationID == temp.PULocationID_,\n",
    "        data.DOLocationID == temp.DOLocationID_]\n",
    "\n",
    "data = data.join(temp, on=cond) \\\n",
    "            .select([data.lpep_pickup_datetime, data.PULocationID, \n",
    "                     data.DOLocationID, data.duration, temp['avg(duration_)']]).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumn(\"hour\", hour('lpep_pickup_datetime')) \\\n",
    "            .withColumn(\"weekday\", dayofweek('lpep_pickup_datetime')) \\\n",
    "            .withColumn(\"month\", month('lpep_pickup_datetime'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoderEstimator(inputCols=['PULocationID', 'DOLocationID', 'hour', 'weekday', 'month'],\n",
    "                                outputCols=['PULocationIDVec', 'DOLocationIDVec', 'hourVec', 'weekdayVec', 'monthVec'])\n",
    "vectorAssembler = VectorAssembler(inputCols = ['PULocationIDVec', 'DOLocationIDVec', 'hourVec', 'weekdayVec', 'monthVec', 'avg(duration_)'], outputCol = 'features')\n",
    "lr = LinearRegression(featuresCol='features',labelCol='duration')\n",
    "pipeline = Pipeline(stages=[encoder, vectorAssembler, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = data.randomSplit([0.7, 0.3])\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(predictionCol='prediction', labelCol='duration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.evaluate(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.evaluate(predict, {evaluator.metricName: \"r2\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_hist = predict.select(col('prediction') - col('duration')).rdd.flatMap(lambda x: x).histogram(20)\n",
    "duration_hist_pd = pd.DataFrame(zip(*duration_hist), columns=['bins', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=duration_hist_pd, x='bins', y='count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.select(date_trunc('hour', col('lpep_pickup_datetime')).alias('lpep_pickup_datetime'),\n",
    "                'PULocationID') \\\n",
    "        .groupBy(['lpep_pickup_datetime', 'PULocationID']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumn('month_1', add_months('lpep_pickup_datetime', -1))\n",
    "data.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = data.select(col('lpep_pickup_datetime').alias('lpep_pickup_datetime_'), \n",
    "                   col('PULocationID').alias('PULocationID_'),\n",
    "                   col('count').alias('count_'))\n",
    "temp.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = [data.month_1 == temp.lpep_pickup_datetime_, \n",
    "        data.PULocationID == temp.PULocationID_]\n",
    "\n",
    "data = data.join(temp, on=cond) \\\n",
    "            .select([data.lpep_pickup_datetime, data.PULocationID, \n",
    "                     data['count'], temp['count_']]).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumn(\"hour\", hour('lpep_pickup_datetime')) \\\n",
    "            .withColumn(\"weekday\", dayofweek('lpep_pickup_datetime')) \\\n",
    "            .withColumn(\"month\", month('lpep_pickup_datetime'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoderEstimator(inputCols=['PULocationID', 'hour', 'weekday', 'month'],\n",
    "                                outputCols=['PULocationIDVec', 'hourVec', 'weekdayVec', 'monthVec'])\n",
    "vectorAssembler = VectorAssembler(inputCols = ['PULocationIDVec', 'hourVec', 'weekdayVec', 'monthVec', 'count_'], outputCol = 'features')\n",
    "lr = LinearRegression(featuresCol='features',labelCol='count')\n",
    "pipeline = Pipeline(stages=[encoder, vectorAssembler, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = data.randomSplit([0.7, 0.3])\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(predictionCol='prediction', labelCol='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvs = TrainValidationSplit(estimator=pipeline,\n",
    "                           estimatorParamMaps=paramGrid,\n",
    "                           evaluator=evaluator,\n",
    "                           trainRatio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tvs.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = model.bestModel.stages[2].summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.evaluate(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.evaluate(predict, {evaluator.metricName: \"r2adj\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Моделирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.reshape((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((5,5))\n",
    "x[:,:-1] = a\n",
    "x[:,-1] = range(1,6)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
